{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-3-c8b10386149a>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc4a2d53828>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADRRJREFUeJzt3WGoXPWZx/Hfz9iIpEHUTExIo7dbZFUU02UICy6StVrsUrlWaGjATQqlty8iWOgLRcEaiCjLtl1fLIXbNTSR1jaQqhcNu5Ww4FZUHEWqbXa3KnfbbEJyYxpiBC3GZ1/ck+Wa3ntmMnPOnLl5vh+QmTnPmTkPJ/7umZn/mfN3RAhAPuc13QCAZhB+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJnT/Mja1YsSLGxsaGuUkglenpaR09etS9rDtQ+G3fKulRSUsk/UtEPFK2/tjYmDqdziCbBFCi3W73vG7fb/ttL5H0z5K+JOkaSZtsX9Pv6wEYrkE+86+X9FZEvBMRf5L0M0nj1bQFoG6DhH+NpD/MeXygWPYJtidsd2x3ZmZmBtgcgCoNEv75vlT4s98HR8RkRLQjot1qtQbYHIAqDRL+A5LWznn8GUkHB2sHwLAMEv5XJF1p+7O2l0r6mqSpatoCULe+h/oi4iPbd0n6N80O9e2IiN9U1hmAWg00zh8ReyXtragXAEPE6b1AUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kNdAsvbanJb0n6ZSkjyKiXUVTAOo3UPgLfxsRRyt4HQBDxNt+IKlBwx+Sfmn7VdsTVTQEYDgGfdt/Q0QctL1S0nO2/zMinp+7QvFHYUKSLr/88gE3B6AqAx35I+JgcXtE0pOS1s+zzmREtCOi3Wq1BtkcgAr1HX7by2wvP31f0hclvVlVYwDqNcjb/sskPWn79Ov8NCL+tZKuANSu7/BHxDuSrq+wFwBDxFAfkBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gqSqu3rsofPjhh6X1hx56qLS+ffv2KtsZGVNTU6X1q666qrReXM+hEdu2bSutP/vsswvW9u/fX/rclStX9tXTYsKRH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSSjPO320cv1u9yfHsOo2Pj5fWI6K0vlj3y2233VZa3717d2n9iiuuqLKdRnDkB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkuo7z294h6cuSjkTEtcWySyT9XNKYpGlJGyPij/W1Obhuv8dfrOPV6E+n0ymtb9y4sbT+zDPPlNZbrdZZ9zRsvRz5fyzp1jOW3StpX0RcKWlf8RjAItI1/BHxvKRjZywel7SzuL9T0u0V9wWgZv1+5r8sIg5JUnF77l/zCDjH1P6Fn+0J2x3bnZmZmbo3B6BH/Yb/sO3VklTcHlloxYiYjIh2RLQXw5cgQBb9hn9K0pbi/hZJT1fTDoBh6Rp+209IelHSX9o+YPsbkh6RdIvt30m6pXgMYBHpOs4fEZsWKH2h4l4wgq6//vrS+pIlS0rrb7/99oK1EydO9NVTFS666KLS+j333FNav/TSS6tspxGc4QckRfiBpAg/kBThB5Ii/EBShB9IKs2luzdv3lxaf/zxx/t+7bvvvru0fsEFF/T92k17+OGHB3r+nj17Fqx1+zf54IMPBtp2mTvuuGOg+rmAIz+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJOVuUzBXqd1uR7dLJtfl/fffL62/+OKLfb/2hg0bSuvnn5/mdIqzsmrVqtL6oJd9K/vZ7gsvvFD63KuvvnqgbTel3W6r0+n0dB16jvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kFSaAehly5aV1m+++eYhdZLLAw88sGDt2LEz53+t1po1axasLdZx/Cpx5AeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpLqO89veIenLko5ExLXFsgclfVPS6R9c3xcRe+tqEqPr3XffLa2/9NJLC9ZOnTo10LZvvPHG0vrU1NRAr3+u6+XI/2NJt86z/AcRsa74j+ADi0zX8EfE85LqPRULwNAN8pn/Ltu/tr3D9sWVdQRgKPoN/w8lfU7SOkmHJH1voRVtT9ju2O4Mek02ANXpK/wRcTgiTkXEx5J+JGl9ybqTEdGOiHar1eq3TwAV6yv8tlfPefgVSW9W0w6AYellqO8JSRskrbB9QNJ3JW2wvU5SSJqW9K0aewRQg67hj4hN8yx+rIZeMIKOHz9eWp+YmCit79u3r8p2PuH+++8vrS9fvry2bZ8LOMMPSIrwA0kRfiApwg8kRfiBpAg/kFSaS3ejP91+svvUU08NqRNUjSM/kBThB5Ii/EBShB9IivADSRF+ICnCDyTFOD9KRcRA9UGsXr26tL5ixYratp0BR34gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIpxfpTatWtXad12bdvevHlzaX3dunW1bTsDjvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kFTXcX7bayXtkrRK0seSJiPiUduXSPq5pDFJ05I2RsQf62sVTdi+fXtpvc5xftSrlyP/R5K+ExFXS/prSVttXyPpXkn7IuJKSfuKxwAWia7hj4hDEfFacf89SfslrZE0LmlnsdpOSbfX1SSA6p3VZ37bY5I+L+llSZdFxCFp9g+EpJVVNwegPj2H3/anJe2R9O2IOHEWz5uw3bHdmZmZ6adHADXoKfy2P6XZ4P8kIn5RLD5se3VRXy3pyHzPjYjJiGhHRLvValXRM4AKdA2/Z7/OfUzS/oj4/pzSlKQtxf0tkp6uvj0AdenlJ703SPp7SW/Yfr1Ydp+kRyTttv0NSb+X9NV6WkSd7rzzzsa2fd1115XWt23bNqROcuoa/oj4laSFBnO/UG07AIaFM/yApAg/kBThB5Ii/EBShB9IivADSXHp7uSOHz/e2La7nWOwdOnSIXWSE0d+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iKcX6UiojS+iCX7t66dWvfz8XgOPIDSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKM86MUU3CfuzjyA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBSXcf5ba+VtEvSKkkfS5qMiEdtPyjpm5JmilXvi4i9dTWKetx0002l9b17+Sc9V/Vyks9Hkr4TEa/ZXi7pVdvPFbUfRMQ/1tcegLp0DX9EHJJ0qLj/nu39ktbU3RiAep3VZ37bY5I+L+nlYtFdtn9te4ftixd4zoTtju3OzMzMfKsAaEDP4bf9aUl7JH07Ik5I+qGkz0lap9l3Bt+b73kRMRkR7Yhot1qtCloGUIWewm/7U5oN/k8i4heSFBGHI+JURHws6UeS1tfXJoCqdQ2/Z3/W9Zik/RHx/TnLV89Z7SuS3qy+PQB1cQ+XZv4bSf8h6Q3NDvVJ0n2SNmn2LX9Impb0reLLwQW12+3odDoDtoxhOu+88uPDID/5PXnyZGn9wgsv7Pu1s2q32+p0Oj39o/Tybf+vJM33YgwAA4sYZ/gBSRF+ICnCDyRF+IGkCD+QFOEHkuLS3Sg1NTVVWh8fHx9SJ6gaR34gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSKrr7/kr3Zg9I+l/5ixaIeno0Bo4O6Pa26j2JdFbv6rs7YqI6Ol6eUMN/59t3O5ERLuxBkqMam+j2pdEb/1qqjfe9gNJEX4gqabDP9nw9suMam+j2pdEb/1qpLdGP/MDaE7TR34ADWkk/LZvtf1ftt+yfW8TPSzE9rTtN2y/brvR64wX06Adsf3mnGWX2H7O9u+K23mnSWuotwdt/2+x7163/XcN9bbW9r/b3m/7N7bvLpY3uu9K+mpkvw39bb/tJZL+W9Itkg5IekXSpoj47VAbWYDtaUntiGh8TNj2jZJOStoVEdcWy/5B0rGIeKT4w3lxRNwzIr09KOlk0zM3FxPKrJ47s7Sk2yV9XQ3uu5K+NqqB/dbEkX+9pLci4p2I+JOkn0niihDziIjnJR07Y/G4pJ3F/Z2a/Z9n6BbobSRExKGIeK24/56k0zNLN7rvSvpqRBPhXyPpD3MeH9BoTfkdkn5p+1XbE003M4/LTs+MVNyubLifM3WduXmYzphZemT2XT8zXletifDPN/vPKA053BARfyXpS5K2Fm9v0ZueZm4elnlmlh4J/c54XbUmwn9A0to5jz8j6WADfcwrIg4Wt0ckPanRm3348OlJUovbIw338/9Gaebm+WaW1gjsu1Ga8bqJ8L8i6Urbn7W9VNLXJJVfJXJIbC8rvoiR7WWSvqjRm314StKW4v4WSU832MsnjMrMzQvNLK2G992ozXjdyEk+xVDGP0laImlHRDw09CbmYfsvNHu0l2avbPzTJnuz/YSkDZr91ddhSd+V9JSk3ZIul/R7SV+NiKF/8bZAbxt0ljM319TbQjNLv6wG912VM15X0g9n+AE5cYYfkBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGk/g8Iw7GOQ5+CbgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc4a2dce5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_image = mnist.train.next_batch(1)[0]\n",
    "print(sample_image.shape)\n",
    "\n",
    "sample_image = sample_image.reshape([28, 28])\n",
    "plt.imshow(sample_image, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(images, reuse_variables=None):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=reuse_variables) as scope:\n",
    "        # First convolutional and pool layers\n",
    "        # This finds 32 different 5 x 5 pixel features\n",
    "        d_w1 = tf.get_variable('d_w1', [5, 5, 3, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b1 = tf.get_variable('d_b1', [32], initializer=tf.constant_initializer(0))\n",
    "        d1 = tf.nn.conv2d(input=images, filter=d_w1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        d1 = d1 + d_b1\n",
    "        d1 = tf.nn.relu(d1)\n",
    "        d1 = tf.nn.avg_pool(d1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        # Second convolutional and pool layers\n",
    "        # This finds 64 different 5 x 5 pixel features\n",
    "        d_w2 = tf.get_variable('d_w2', [5, 5, 32, 64], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b2 = tf.get_variable('d_b2', [64], initializer=tf.constant_initializer(0))\n",
    "        d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        d2 = d2 + d_b2\n",
    "        d2 = tf.nn.relu(d2)\n",
    "        d2 = tf.nn.avg_pool(d2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        # First fully connected layer\n",
    "        d_w3 = tf.get_variable('d_w3', [7 * 7 * 64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b3 = tf.get_variable('d_b3', [1024], initializer=tf.constant_initializer(0))\n",
    "        d3 = tf.reshape(d2, [-1, 7 * 7 * 64])\n",
    "        d3 = tf.matmul(d3, d_w3)\n",
    "        d3 = d3 + d_b3\n",
    "        d3 = tf.nn.relu(d3)\n",
    "\n",
    "        # Second fully connected layer\n",
    "        d_w4 = tf.get_variable('d_w4', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b4 = tf.get_variable('d_b4', [1], initializer=tf.constant_initializer(0))\n",
    "        d4 = tf.matmul(d3, d_w4) + d_b4\n",
    "\n",
    "        # d4 contains unscaled values\n",
    "        return d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, batch_size, z_dim):\n",
    "    g_w1 = tf.get_variable('g_w1', [z_dim, 3136], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b1 = tf.get_variable('g_b1', [3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g1 = tf.matmul(z, g_w1) + g_b1\n",
    "    g1 = tf.reshape(g1, [-1, 56, 56, 1])\n",
    "    g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='g_b1')\n",
    "    g1 = tf.nn.relu(g1)\n",
    "\n",
    "    # Generate 50 features\n",
    "    g_w2 = tf.get_variable('g_w2', [3, 3, 1, z_dim/2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b2 = tf.get_variable('g_b2', [z_dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g2 = tf.nn.conv2d(g1, g_w2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g2 = g2 + g_b2\n",
    "    g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='g_b2')\n",
    "    g2 = tf.nn.relu(g2)\n",
    "    g2 = tf.image.resize_images(g2, [56, 56])\n",
    "\n",
    "    # Generate 25 features\n",
    "    g_w3 = tf.get_variable('g_w3', [3, 3, z_dim/2, z_dim/4], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b3 = tf.get_variable('g_b3', [z_dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g3 = tf.nn.conv2d(g2, g_w3, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g3 = g3 + g_b3\n",
    "    g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope='g_b3')\n",
    "    g3 = tf.nn.relu(g3)\n",
    "    g3 = tf.image.resize_images(g3, [56, 56])\n",
    "\n",
    "    # Final convolution with one output channel\n",
    "    g_w4 = tf.get_variable('g_w4', [1, 1, z_dim/4, 1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b4 = tf.get_variable('g_b4', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g4 = tf.nn.conv2d(g3, g_w4, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g4 = g4 + g_b4\n",
    "    g4 = tf.sigmoid(g4)\n",
    "    \n",
    "    # Dimensions of g4: batch_size x 28 x 28 x 1\n",
    "    return g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dimensions = 100\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image_output = generator(z_placeholder, 1, z_dimensions)\n",
    "z_batch = np.random.normal(0, 1, [1, z_dimensions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd5132e7f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    generated_image = sess.run(generated_image_output,\n",
    "                                feed_dict={z_placeholder: z_batch})\n",
    "    generated_image = generated_image.reshape([28, 28])\n",
    "    plt.imshow(generated_image, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 1 and 3 for 'Conv2D_3' (op: 'Conv2D') with input shapes: [?,28,28,1], [5,5,3,32].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    687\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 1 and 3 for 'Conv2D_3' (op: 'Conv2D') with input shapes: [?,28,28,1], [5,5,3,32].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9c1a56af3a81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Gz holds the generated images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mDx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m# Dx will hold discriminator prediction probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# for the real MNIST images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-73131124e418>\u001b[0m in \u001b[0;36mdiscriminator\u001b[0;34m(images, reuse_variables)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0md_w1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'd_w1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_normal_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstddev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0md_b1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'd_b1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_w1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md_b1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0;34m\"Conv2D\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m         data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[1;32m    954\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3290\u001b[0m           op_def=op_def)\n\u001b[1;32m   3291\u001b[0m       self._create_op_helper(ret, compute_shapes=compute_shapes,\n\u001b[0;32m-> 3292\u001b[0;31m                              compute_device=compute_device)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[0;34m(self, op, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3330\u001b[0m     \u001b[0;31m# compute_shapes argument.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3332\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3333\u001b[0m     \u001b[0;31m# TODO(b/XXXX): move to Operation.__init__ once _USE_C_API flag is removed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3334\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_set_shapes_for_outputs_c_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2495\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2496\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_set_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_set_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2467\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2469\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2470\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2398\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2399\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2401\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 1 and 3 for 'Conv2D_3' (op: 'Conv2D') with input shapes: [?,28,28,1], [5,5,3,32]."
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 50\n",
    "\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions], name='z_placeholder') \n",
    "# z_placeholder is for feeding input noise to the generator\n",
    "\n",
    "x_placeholder = tf.placeholder(tf.float32, shape = [None,28,28,1], name='x_placeholder') \n",
    "# x_placeholder is for feeding input images to the discriminator\n",
    "\n",
    "Gz = generator(z_placeholder, batch_size, z_dimensions) \n",
    "# Gz holds the generated images\n",
    "\n",
    "Dx = discriminator(x_placeholder) \n",
    "# Dx will hold discriminator prediction probabilities\n",
    "# for the real MNIST images\n",
    "\n",
    "Dg = discriminator(Gz, reuse_variables=True)\n",
    "# Dg will hold discriminator prediction probabilities for generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator loss functions\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dx, labels = tf.ones_like(Dx)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.zeros_like(Dg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator loss function\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.ones_like(Dg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d_w1:0', 'd_b1:0', 'd_w2:0', 'd_b2:0', 'd_w3:0', 'd_b3:0', 'd_w4:0', 'd_b4:0']\n",
      "['g_w1:0', 'g_b1:0', 'g_b1/beta:0', 'g_w2:0', 'g_b2:0', 'g_b2/beta:0', 'g_w3:0', 'g_b3:0', 'g_b3/beta:0', 'g_w4:0', 'g_b4:0']\n"
     ]
    }
   ],
   "source": [
    "# keep organized lists of discriminator and generator trainable variables\n",
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]\n",
    "\n",
    "print([v.name for v in d_vars])\n",
    "print([v.name for v in g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the discriminator\n",
    "d_trainer_fake = tf.train.AdamOptimizer(0.0003).minimize(d_loss_fake, var_list=d_vars)\n",
    "d_trainer_real = tf.train.AdamOptimizer(0.0003).minimize(d_loss_real, var_list=d_vars)\n",
    "\n",
    "# Train the generator\n",
    "g_trainer = tf.train.AdamOptimizer(0.0001).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From this point forward, reuse variables\n",
    "tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "tf.summary.scalar('Generator_loss', g_loss)\n",
    "tf.summary.scalar('Discriminator_loss_real', d_loss_real)\n",
    "tf.summary.scalar('Discriminator_loss_fake', d_loss_fake)\n",
    "\n",
    "images_for_tensorboard = generator(z_placeholder, batch_size, z_dimensions)\n",
    "tf.summary.image('Generated_images', images_for_tensorboard, 5)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-15-504b7f2367e4>(13)<module>()\n",
      "-> _, __, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake],\n",
      "(Pdb) typeof(real_image_batch)\n",
      "*** NameError: name 'typeof' is not defined\n",
      "(Pdb) type(real_image_batch)\n",
      "<class 'numpy.ndarray'>\n",
      "(Pdb) real_image_batch.shape\n",
      "(50, 28, 28, 1)\n",
      "(Pdb) type(mnist.train.next_batch(batch_size))\n",
      "<class 'tuple'>\n",
      "(Pdb) mnist.train.next_batch(batch_size)[1]\n",
      "array([6, 9, 5, 3, 1, 6, 7, 7, 4, 1, 4, 4, 6, 9, 0, 8, 6, 0, 7, 8, 3, 2,\n",
      "       7, 6, 7, 1, 7, 9, 9, 2, 2, 1, 2, 8, 7, 4, 0, 0, 0, 4, 2, 9, 6, 5,\n",
      "       8, 6, 9, 0, 2, 3], dtype=uint8)\n",
      "(Pdb) mnist.train.next_batch(batch_size)[1].shape\n",
      "(50,)\n",
      "--KeyboardInterrupt--\n",
      "(Pdb) quit()\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-504b7f2367e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mreal_image_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       _, __, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake],\n\u001b[0m\u001b[1;32m     14\u001b[0m                                              {x_placeholder: real_image_batch, z_placeholder: z_batch})\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-504b7f2367e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mreal_image_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       _, __, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake],\n\u001b[0m\u001b[1;32m     14\u001b[0m                                              {x_placeholder: real_image_batch, z_placeholder: z_batch})\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "\n",
    "# actual training, 3-30hrs to run\n",
    "if True:\n",
    "  sess = tf.Session()\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "\n",
    "  # Pre-train discriminator\n",
    "  for i in range(300):\n",
    "      z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "      real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n",
    "      pdb.set_trace()\n",
    "      _, __, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake],\n",
    "                                             {x_placeholder: real_image_batch, z_placeholder: z_batch})\n",
    "\n",
    "      if(i % 100 == 0):\n",
    "          print(\"dLossReal:\", dLossReal, \"dLossFake:\", dLossFake)\n",
    "\n",
    "  # Train generator and discriminator together\n",
    "  for i in range(100000):\n",
    "      real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n",
    "      z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "\n",
    "      # Train discriminator on both real and fake images\n",
    "      _, __, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake],\n",
    "                                             {x_placeholder: real_image_batch, z_placeholder: z_batch})\n",
    "\n",
    "      # Train generator\n",
    "      z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "      _ = sess.run(g_trainer, feed_dict={z_placeholder: z_batch})\n",
    "\n",
    "      if i % 10 == 0:\n",
    "          # Update TensorBoard with summary statistics\n",
    "          z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "          summary = sess.run(merged, {z_placeholder: z_batch, x_placeholder: real_image_batch})\n",
    "          writer.add_summary(summary, i)\n",
    "\n",
    "      if i % 100 == 0:\n",
    "          # Every 100 iterations, show a generated image\n",
    "          print(\"Iteration:\", i, \"at\", datetime.datetime.now())\n",
    "          z_batch = np.random.normal(0, 1, size=[1, z_dimensions])\n",
    "          generated_images = generator(z_placeholder, 1, z_dimensions)\n",
    "          images = sess.run(generated_images, {z_placeholder: z_batch})\n",
    "          plt.imshow(images[0].reshape([28, 28]), cmap='Greys')\n",
    "          plt.show()\n",
    "\n",
    "          # Show discriminator's estimate\n",
    "          im = images[0].reshape([1, 28, 28, 1])\n",
    "          result = discriminator(x_placeholder)\n",
    "          estimate = sess.run(result, {x_placeholder: im})\n",
    "          print(\"Estimate:\", estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-31739b3e6d7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pretrained-model/pretrained_gan.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mz_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dimensions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mz_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dimensions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'z_placeholder'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'pretrained-model/pretrained_gan.ckpt')\n",
    "    z_batch = np.random.normal(0, 1, size=[10, z_dimensions])\n",
    "    z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions], name='z_placeholder') \n",
    "    generated_images = generator(z_placeholder, 10, z_dimensions)\n",
    "    images = sess.run(generated_images, {z_placeholder: z_batch})\n",
    "    for i in range(10):\n",
    "        plt.imshow(images[i].reshape([28, 28]), cmap='Greys')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
